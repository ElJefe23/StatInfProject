?geom_smooth()
?axis()
?llines()
?lines
?lpoints()
library("sqldf", lib.loc="~/R/win-library/3.1")
myURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(myURL,dest.file="./Fss06pid.csv")
download.file(myURL,destfile="./Fss06pid.csv")
?read.csv()
acs<-read.csv("./Fss06pid.csv")
?unique()
?nchar()
library(httr)
html2=GET(http://biostat.jhsph.edu/~jleek/contact.html)
html2=GET("http://biostat.jhsph.edu/~jleek/contact.html")
content2=content(html2,as"text")
content2=content(html2,as="text")
parsedHTML=htmlParse(content2,asText=TRUE)
library(xml)
library(XML)
parsedHTML=htmlParse(content2,asText=TRUE)
head(content2)
parsedHTML
parsedHTML[10]
parsedHTML
nchar("<link rel="stylesheet" href="images/PixelGreen.css" type="text/css">")
?nchar()
conj=url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode=readLines(conj)
htmlCode=readLines(conj)
htmlCode
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
?read.file()
?read.table()
wtf<-read.table("getdata_wksst810.for")
wtf<-read.table("./getdata_wksst810.for")
wtf<-read.table("./getdata_wksst8110.for")
wtf<-read.table("./getdata_wksst8110.for",header=TRUE)
wft<-read.csv("./Quiz2_Q5.csv",header=FALSE)
sum(wft[,4])
library(httr)
myAuth<-"2fa09612085a4e05df0ea84e7c108ebc26ace188"
rawPull<-curl -i -H 'Authorization token 2fa09612085a4e05df0ea84e7c108ebc26ace188' https://api.github.com/users/jtleek/repos
?curl()
?get()
?GET
rawPull<-GET(url='https://api.github.com/users/jtleek/repos')
json1=content(rawPull)
install.packages("jsonlite")
library("jsonlite", lib.loc="~/R/win-library/3.1")
json1=content(rawPull)
json2=jsonlite::fromJSON(toJSON(json1))
json2
?download.file()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile="./ss06hid.csv")
q1Data<-read.csv("./ss06hid.csv")
q1Data$ACR
logVect<-which(q1Data$ACR==3 & q1Data$AGS==6)
q1Ans<-q1Data[logVect,]
head(q1Ans)
install.packages("jpeg")
library("jpeg", lib.loc="~/R/win-library/3.1")
?read.jpeg()
?jpeg()
?readJPEG()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg",destfile="./Instruct.jpg")
picDat<-readJPEG("./Instruct.jpg",native=TRUE)
?quantile()
quantile(pictDat,probs=c(0.3,0.8))
quantile(picDat,probs=c(0.3,0.8))
quantile(picDat)
quantile(picDat,probs=c(0.3,0.8),na.rm=TRUE)
?download.file()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg",destfile="./Instruct.jpg",mode="wb")
picDat<-readJPEG("./Instruct.jpg",native=TRUE)
quantile(picDat,probs=c(0.3,0.8),na.rm=TRUE)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="./GDP.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="./Edu.csv")
GDPdata<-read.csv("./GDP.csv")
eduData<-read.csv("./Edu.csv")
head(eduData)
head(GDPdata)
GDPdata<-read.csv("./GDP.csv")
head(GDPdata)
tail(GDPdata)
GDPdata<-read.csv("./GDP.csv")
GDPdata<-read.csv("./GDP2.csv")
head(eduData)
jumbo<-merge(GDPdata,eduData,by.x="ID",by.y="CountryCode",all=TRUE)
head(jumbo)
sort(jumbo$GDP_USD,decreasing=TRUE)
names(jumbo)
sort(jumbo$Ranking,decreasing=TRUE)
jumboSort<-jumbo[sort(jumbo$Ranking,decreasing=TRUE),]
jumboSort$Long.Name
?merge()
GDPdata<-read.csv("./Quiz3Q3.csv")
jumbo<-merge(GDPdata,eduData,by.x="CountryCode",by.y="CountryCode",all=FALSE)
jumboSpl<-split(jumbo$GDP.Rank,jumbo$Income.Group)
sapply(jumboSpl,average)
sapply(jumboSpl,sum)
sapply(jumboSpl,avg)
sapply(jumboSpl,mean)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
jumbo$GDP.Group=cut2(jumbo$GDP.Rank,g=5)
table(jumbo$GDP.Group,jumbo.$Income.Group)
table(jumbo$GDP.Group,jumbo$Income.Group)
NEI <- readRDS("./EDA_Project2/summarySCC_PM25.rds")
SCC <- readRDS("./EDA_Project2/Source_Classification_Code.rds")
head(NEI,3)
NEI$ycf<-factor(NEI$year)
?split()
NEI_list<-split(NEI,NEI$ycf)
?sapply()
lapply(NEI_list,sum(NEI_list$Emissions))
lapply(NEI_list,sum(Emissions))
?sum()
sum(NEI$Emissions)
NEI_list$Emissions
NEI_list[Emissions]
NEI_list[,Emissions]
NEI_list[Emissions""]
NEI_list["Emissions"]
NEI_list[,"Emissions"]
?tapply()
tapply(NEI$Emissions,NEI$year,sum)
NEI <- readRDS("./EDA_Project2/summarySCC_PM25.rds")
SCC <- readRDS("./EDA_Project2/Source_Classification_Code.rds")
tapply(NEI$Emissions,NEI$year,sum)
install.packages("plyr")
library("plyr", lib.loc="~/R/win-library/3.1")
?ddply()
ddply(NEI,.(Year),summarize,sum(Emissions))
ddply(NEI,NEI$Year,summarize,sum(Emissions))
ddply(NEI,.(year),summarize,sum(Emissions))
?ddply()
ddply(NEI,.(year),summarize,total=sum(Emissions))
totalByYear<-ddply(NEI,.(year),summarize,total=sum(Emissions))
?plot()
plot(totalByYear$year,totalByYear$total,type="b",main="Yearly Trend In Total Emissions")
plot(totalByYear$year,totalByYear$total,type="b",main="Yearly Trend In Total Emissions",xlab="Year",ylab="Total Emissions, tons")
?subset()
justBMore<-subset(NEI,NEI$fips=="24510")
## Here to require plyr package
## Comment the following statement fully
totalByYear<-ddply(NEI,.(year),summarize,total=sum(Emissions))
totalByYear<-ddply(justBMore,.(year),summarize,total=sum(Emissions))
plot(totalByYear$year,totalByYear$total,type="b",main="Yearly Trend In Total Emissions, BMore",xlab="Year",ylab="Total Emissions, tons in BMore")
totalByTypeYear<-ddply(justBMore,.(type, year), summarize, total=sum(Emissions))
totalByTypeYear
qplot(year,total,data=totalByTypeYear,facets=.~type)
library("ggplot2", lib.loc="~/R/win-library/3.1")
qplot(year,total,data=totalByTypeYear,facets=.~type)
SCC$Data.Category
SCC$EI.Sector
?levels()
levels(SCC$SCC.Level.One)
levels(SCC$SCC.Level.Two)
levels(SCC$EI.Sector)
justCoalSources<-SCC[SCC$EI.Sector==13,SCC]
justCoalSources<-SCC[(SCC$EI.Sector==13),SCC]
justCoal<-SCC$EI.Sector=="Fuel Comb - Comm/Institutional - Coal"
justCoalSources<-SCC[justCoal,SCC]
justCoalSources<-SCC[justCoal,"SCC"]
levels(justCoalSources)
justCoalSources<-SCC[justCoal,]
head(justCoalSources)
justCoalSources$SCC
justCoalSCC<-justCoalSources$SCC
justCoalSCC
justCoalINT<-as.int(justCoalSCC)
justCoalINT<-as.integer(justCoalSCC)
justCoalINT
justCoalChr<-as.character(justCoalSCC)
NEI_Coal<-NEI$SCC%in%justCoalChr
count(NEI_Coal)
onlyCoalEmiss<-NEI[NEI_Coal,]
totalCoalByYear<-ddply(onlyCoalEmiss,.(year),total=sum(Emissions))
totalCoalByYear<-ddply(onlyCoalEmiss,.(year),summarize,total=sum(Emissions))
totalCoalByYear
plot(totalCoalByYear$year,totalCoalByYear$total,type="b",main="Yearly Trend in Emissions from Coal" xlab="Year",ylab="Total Emissions, tons")
plot(totalCoalByYear$year,totalCoalByYear$total,type="b",main="Yearly Trend in Emissions from Coal" ,xlab="Year",ylab="Total Emissions, tons")
NEI <- readRDS("./EDA_Project2/summarySCC_PM25.rds")
SCC <- readRDS("./EDA_Project2/Source_Classification_Code.rds")
levels(SCC$EI.Sector)
levels(SCC$SCC.Level.One)
levels(SCC$Option.Group)
levels(SCC$Option.Set)
?grep()
motVehic<-SCC[grep("Mobile",SCC$EI.Sector),]
motVehic<-SCC[grep("Mobile",SCC$EI.Sector),"SCC"]
motVehicChr<-as.character(motVehic)
justBMore<-subset(NEI,NEI$fips=="24510")
BMore_Motors<-justBMore$SCC%in%motVehicChr
justBMoreMotor<-justBMore[BMore_Motors,]
BMoreMotorByYear<-ddply(justBMoreMotor,.(year),summarize,total=sum(Emissions))
plot(BMoreMotorByYear$year,BMoreMotorByYear$total,main="Baltimore Motor Vehicle Emissions",type="b",xlab="Year",ylab="Total Emissions, tons")
twoCities<-subset(NEI,NEI$fips%in%c("24510","06037"))
twoCities_Motors<-twoCities$SCC%in%motVehicChr
twoCitiesMotEmiss<-twoCities[twoCities_Motors,]
twoCitiesByYear<-ddply(twoCtiesMotEmiss,.(year,fips),summarize,total=sum(Emissions))
twoCitiesByYear<-ddply(twoCitiesMotEmiss,.(year,fips),summarize,total=sum(Emissions))
twoCitiesByYear
twoCitiesByYear<-ddply(twoCitiesMotEmiss,.(fips, year),summarize,total=sum(Emissions))
twoCitiesByYear<-ddply(twoCitiesMotEmiss,.(fips, year),summarize,total=sum(Emissions))
twoCitiesByYear
qplot(year,total,data=twoCitiesByYear,facets=.~fips)
?read.table()
colLabels<-read.table("./y_train.txt",sep="")
colLabels<-read.table("./features.txt",sep="")
colLabels<-read.table("./features.txt",sep="",stringsAsFactors=FALSE)
?grep()
goodLabels<-grep("mean",colLabels$V2)
goodLabels<-grep("mean",colLabels$V2,value="TRUE")
goodLabels2<-grep("std",colLabels$V2,value="TRUE")
goodLabels
goodLabels<-grep("mean()",colLabels$V2,value="TRUE")
goodLabels
goodLabels<-grep("mean | std",colLabels$V2,value="TRUE")
goodLabels<-grep("mean(",colLabels$V2,value="TRUE")
goodLabels<-grep("mean",colLabels$V2,value="TRUE")
goodLabels<-grep("mean/(/",colLabels$V2,value="TRUE")
goodLabels<-grep("mean\(\",colLabels$V2,value="TRUE")
goodLabels<-grep("*mean",colLabels$V2,value="TRUE",fixed="TRUE")
goodLabels<-grep("mean",colLabels$V2,value="TRUE",fixed="TRUE")
goodLabels<-grep("mean\(",colLabels$V2,value="TRUE",fixed="TRUE")
?contains()
goodLabels<-grepl("mean",colLabels$V2)
all_mean<-grepl("mean",colLabels$V2)
all_std<-grepl("std",colLabels$V2)
just_meanFreq<-grepl("meanFreq",colLabels$V2)
count(just_meanFreq)
sum(just_meanFreq)
just_mean<-all_mean!just_meanFreq
just_mean<-all_mean ! just_meanFreq
just_mean<-all_mean &!just_meanFreq
sum(just_mean)
all_kept<-just_mean&all_std
all_kept<-just_mean|all_std
sum(all_kept)
trainData<-read.table("./X_train",sep="")
trainData<-read.table("./X_train.txt",sep="")
keptTrain<-trainData[,all_kept]
?labels()
?col.names()
?colNames()
?row.names()
?read.table()
trainData<-read.table("./X_train.txt",sep="",col.names=colLabels$V2)
keptTrain<-trainData[,all_kept]
activityID<-read.table("./y_train.txt",sep="")
gsub("1","WALKING",activityID)
activityID<-gsub("1","WALKING",activityID)
activityID<-gsub("2","WALKING_UPSTAIRS",activityID)
activityID<-gsub("3","WALKING_DOWNSTAIRS",activityID)
activityID<-gsub("4","SITTING",activityID)
activityID<-gsub("5","STANDING",activityID)
activityID<-gsub("6","LAYING",activityID)
?cbind()
withAct<-cbind(activityID,keptTrain)
head(withAct,3)
activityID<-read.table("./y_train.txt",sep="",col.names="ActID")
withAct<-cbind(activityID,keptTrain)
subjTrain<-read.table("./subject_train.txt",sep="",col.names="SubjID")
withSubjAct<-cbind(subjTrain,withAct)
source('~/Course3_Project/WIP_Course3_Project.R')
testData<-read.table("./X_test.txt",sep="")
## Subset the training data to keep only the desired columns
keptTest<-testData[,all_kept]
## Boom goes the dynamite.
testActID<-read.table("./y_test.txt",sep="")
testWithAct<-cbind(testActID,keptTest)
## Now to bind the Subject ID's
subjTest<-read.table("./subject_test.txt",sep="")
testWithBoth<-cbind(subjTest,testWithAct)
testData<-read.table("./X_test.txt",sep="")
## Subset the training data to keep only the desired columns
keptTest<-testData[,all_kept]
## Boom goes the dynamite.
testActID<-read.table("./y_test.txt",sep="")
testWithAct<-cbind(testActID,keptTest)
## Now to bind the Subject ID's
subjTest<-read.table("./subject_test.txt",sep="")
testWithBoth<-cbind(subjTest,testWithAct)
fullData<-rbind(testWithBoth,withSubjAct)
?rbind
rbind(testWithBoth,withSubjAct)
source('~/Course3_Project/WIP_Course3_Project.R')
fullData<-rbind(testWithBoth,withSubjAct)
library(plyr)
colsForAvg<-colLabels[all_kept]
colsForAvg<-colLabels[all_kept,2]
ddply(fullData,.(SubjID, ActID),summarize,total=sum(colsForAvg))
?ddply()
?tapply()
ddply(fullData,.(SubjID, ActID),summarize,aver=average(colsForAvg$1))
ddply(fullData,.(SubjID, ActID),summarize,aver=average(colsForAvg[1]))
ddply(fullData,.(SubjID, ActID),summarize,aver=mean(colsForAvg[1]))
colsForAvg[1]
ddply(fullData,.(SubjID, ActID),summarize,aver=mean(fullData[,3]))
source('~/Course3_Project/WIP_Course3_Project.R')
monkey<-split(fullData,c("SubjID","ActID"))
monkey<-split(fullData,c(fullData$SubjID,fullData$ActID))
?split()
toroidal<-tapply(monkey,mean)
toroidal<-lapply(monkey,mean)
?lapply()
monkey<-split(fullData,list(fullData$SubjID,fullData$ActID))
sapply(monkey,colmeans)
sapply(monkey,colmeans())
?colmeans()
?colMeans()
sapply(monkey,colMeans())
sapply(monkey,colMeans(x))
sapply(monkey,colMeans(monkey))
lapply(monkey,colMeans())
lapply(monkey,colMeans(x))
lapply(monkey,function(x) colMeans(x,na.rm=TRUE))
sapply(monkey,function(x) colMeans(x,na.rm=TRUE))
terwilliger<-sapply(monkey,function(x) colMeans(x,na.rm=TRUE))
tiger<-lapply(monkey,function(x) colMeans(x,na.rm=TRUE))
?unsplit()
unsplit(tiger,list("SubjID","ActID"))
head(tiger)
source('~/.active-rstudio-document')
wolf<-aggregate(fullData,list(fullData[-(1:2)] ~ SubjID+ActID, data=fullData, FUN=mean)
)
wolf<-aggregate(fullData[-(1:2)] ~ SubjID+ActID, data=fullData, FUN=mean)
?aggregate()
pickle<-fullData[-(1:2)]
type(pickle)
data.frame(pickle)
pickle<-data.frame(fullData[-(1:2)])
wolf<-aggregate(data.frame(fullData[-(1:2)]) ~ SubjID+ActID, data=fullData, FUN=mean)
wolf<-aggregate(list(fullData[-(1:2)]) ~ SubjID+ActID, data=fullData, FUN=mean)
?require()
source('~/EDA_Project2/WIP.R')
?plot()
source('~/EDA_Project2/WIP.R')
source('~/EDA_Project2/WIP.R')
source('~/EDA_Project2/plot1.R')
source('~/EDA_Project2/plot1.R')
source('~/EDA_Project2/plot2.R')
source('~/EDA_Project2/plot4.R')
source('~/EDA_Project2/plot5.R')
source('~/EDA_Project2/plot3.R')
source('~/EDA_Project2/plot3.R')
source('~/EDA_Project2/plot6.R')
?labs()
g<-gqplot(year,total,data=twoCitiesByYear,facets=.~fips)
print(g+ylab("Total Motor Vehicle Emissions, tons"))
g+ylab("Total Motor Vehicle Emission, tons")
g<-qplot(year,total,data=twoCitiesByYear,facets=.~fips)
print(g+ylab("Total Motor Vehicle Emissions, tons"))
?qplot
levels(twoCitiesByYear$fips)
?as.factor()
source('~/EDA_Project2/plot6.R')
qplot(year,total,data=twoCitiesByYear,facets=.~fips, ylab="Total Motor Vehicle Emissions, tons")
source('~/EDA_Project2/plot6.R')
source('~/EDA_Project2/plot3.R')
?multiplot()
?ggplot()
g<-ggplot(totalByYear,aes(year,total))
g<-ggplot(totalByTypeYear,aes(year,total))
g+geom_point(alpha=1/3)+facet_wrap(fips, nrow=2, ncol=2)
g+geom_point(alpha=1/3)+facet_wrap(totalByTypeYear$fips, nrow=2, ncol=2)
g+geom_point(alpha=1/3)+facet_wrap(totalByTypeYear~fips, nrow=2, ncol=2)
?facet_wrap
g+geom_point(alpha=1/3)+facet_wrap(facets=.~fips, nrow=2, ncol=2)
print(g)
g<-ggplot(totalByTypeYear, aes(year,total))+geom_point()
g + facet_grid(.~)
source('~/.active-rstudio-document')
g<-ggplot(totalByTypeYear, aes(year,total))+geom_point()
print(g)
g+facet_grid(.~type)
g+facet_grid(.~type, ncol=2, nrow=2)
g+facet_wrap(.~type, ncol=2, nrow=2)
g+facet_wrap(.~type)
?facet_wrap
?facet_grid
g<-ggplot(totalByTypeYear, aes(year,total))+geom_point()
g+facet_wrap(.~type)
g<-ggplot(totalByTypeYear, aes(year,total))+geom_point()
g+facet_wrap(~type)
g<-ggplot(totalByTypeYear, aes(year,total))+geom_point()
print(g+facet_wrap(~type,ncol=2, nrow=2))
?geom_smooth()
g<-ggplot(totalByTypeYear, aes(year,total))+geom_point() + geom_smooth()
print(g+facet_wrap(~type,ncol=2, nrow=2))
source('~/EDA_Project2/plot3.R')
source('~/EDA_Project2/plot3.R')
source('~/EDA_Project2/plot3.R')
source('~/EDA_Project2/plot3.R')
source('~/Course3_Project/WIP_Course3_Project.R')
wolf<-aggregate(fullData,list(fullData$SubjID,fullData$ActID), FUN=mean)
head(wolf,2)
source('~/Course3_Project/WIP_Course3_Project.R')
source('~/Course3_Project/WIP_Course3_Project.R')
colLabels<-read.table("./features.txt",sep="",stringsAsFactors=FALSE)
all_kept<-<-grepl("mean\\(\\)|std",colLabels$V2)
all_kept<-<-grepl("mean|std",colLabels$V2)
all_kept<-grepl("mean\\(\\)|std",colLabels$V2)
all_kept
all_mean<-grepl("mean\\(\\)|std",colLabels$V2)
just_meanFreq<-grepl("meanFreq",colLabels$V2)
## Since I can't be bothered how to do "not' in a grep statement ...
just_mean<-all_mean &!just_meanFreq
all_std<-grepl("std",colLabels$V2)
## Keep a vector with the std or means
all_kept2<-just_mean|all_std
all_kept2
source('~/Course3_Project/WIP_Course3_Project.R')
pickle<-col.names(tidier)
pickle<-colnames(tidier)
pickle
?write()
write(pickle,"./TidyColumnNames.txt")
?gsub()
pickle<-colnames(tidier)
source('~/Course3_Project/WIP_Course3_Project.R')
betterCols
source('~/Course3_Project/WIP_Course3_Project.R')
betterCols
colnames(tidier)<-betterCols
?write.table()
write.table(tidier,"./tidyData.txt",sep=" ",row.names=FALSE)
?read.table()
read.table("./tidyData.txt", header=TRUE, sep=" ")
pickle<-read.table("./tidyData.txt", header=TRUE, sep=" ")
levels(pickle$ActID)
source('~/Course3_Project/run_analysis.R')
library("ggplot2", lib.loc="~/R/win-library/3.1")
source('~/Course3_Project/run_analysis.R')
install.packages("UsingR")
library("UsingR", lib.loc="~/R/win-library/3.1")
data(father.son)
labels(father.son)
x<-father.son$fheight
(mean(x)+c(1,-1)*qnorm(0.975)*sd(x)/sqrt(length(x)))
poisson.test(600,T=60)$conf
?qnorm
qnorm(0.95,mean=1100,sd=75,lower.tail=TRUE)
?pbinom
pbinom(4,5,0.5)
pbinom(5,5,0.5)
rbinom(4,5,0.5)
pbinom(4,5,0.5,lower.tail=FALSE)
pbinom(3,5,0.5,lower.tail=FALSE)
ppois(10,5*3)
?ppois()
qnorm(0.95,mean=1100,sd=0.75,lower.tail=TRUE)
qnorm(0.95,mean=1100,sd=7.5,lower.tail=TRUE)
?t.test
?dt
qt(0.95,8)
qt(0.975,8)
qt(0.975,18)
sp<-sqrt((9*0.60^2+9*0.68^2)/18)
interval<--2+c(1,-1)*2.101*sp
interval<--2+c(1,-1)*2.101*sp*sqrt(0.2)
-2+c(-1,1)*sp*qt(0.975,18)*sqrt((1/10)+(1/10))
pnorm(0.975)
qnorm(0.975)
6-4+c(-1,1)*qnorm(0.975)*sqrt((0.5^2/100)+(2^2/100))
sp<-sqrt((8*1.5^2+8*1.8^2)/16)
-4+c(-1,1)*sp*qt(0.95,16)*sqrt((1/9)+(1/9))
x1<-c(140,138,150,148,135)
x2<-c(132,135,151,146,130)
?t.test
y=x1-x2
data(ToothGrowth)
?summarize()
?summary()
?describe()
summary(ToothGrowth)
ToothGrowth
hist(ToothGrowth$len)
hist(ToothGrowth[supp="VC",len])
hist(ToothGrowth[supp="VC",1])
hist(ToothGrowth[$supp="VC",1])
smaller<-ToothGrowth[$supp="VC",$len]
smaller<-ToothGrowth[supp="VC",len]
smaller<-ToothGrowth[supp=="VC",len]
ToothGrowth[supp=="VC"]
ToothGrowth[supp=="VC",]
ToothGrowth[$supp=="VC",]
?subset
subset(ToothGrowth, ToothGrowth$supp=="VC")
noodle<-subset(ToothGrowth, ToothGrowth$supp=="VC")
knife<-subset(ToothGrowth, ToothGrowth$supp=="OJ")
mean(noodle$len)
mean(knife$len)
hist(noodle$len)
hist(knife$len)
sd(knife$len)
sd(noodle$len)
?hist()
?t.test()
t.test(knife$len,noodle$len)
t.test(knife$len,noodle$len,conf.level=0.90)
source('~/GitHub/StatInfProject/Course5Project1.R')
setwd('~/GitHub/StatInfProject')
5/sqrt(40)
norm_comp
